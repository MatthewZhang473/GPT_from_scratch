## GPT from scratch

Implementation of a GPT-like decoder-only transformer based on Karpathy's tutorial.

The small model can be trained on CPU within 3 mins.
The scaled model need to be trained on A100 for 15 mins.